# 📆 날짜: 2023-10-09

## 🎯 공통 질문: 브라우저의 렌더링 과정을 순서대로 상세하게 설명해주세요.

### 나라's 답변: <!-- 답변 -->

### 슬기's 답변: <!-- 답변 -->

### 정호's 답변: <!-- 답변 -->

서버에서 응답 받은 HTML 파일이 브라우저에 렌더링되는 과정을 설명해드리겠습니다.
우선 HTML 파일을 파싱하여 DOM을 생성합니다. 만약 이 과정에서 `<link>` 또는 `<style>` 태그를 만난다면
브라우저는 추가적인 CSS 리소스를 가져오게 됩니다. 또한 `<script>` 태그를 만나게 된다면 브라우저는
HTML 파일 파싱을 일시 중단하고 추가적인 리소스를 요청합니다. 그렇기 때문에 일반적으로 `<script>` 는
async 또는 defer 속성을 통해 비동기적으로 가져오는 것을 권장합니다.

HTML 파일 파싱이 끝나면 브라우저는 CSS파일과 함께 인라인 스타일을 사용하여 CSSOM을 생성하고 문서의 각 요소에 스타일을 적용
합니다. 이 과정에서 계산된 스타일이 생성되고, 이를 기반으로 렌더 트리가 구성됩니다. 렌더 트리는 DOM과 CSSOM을 합친 결과물이라고 생각하시면 됩니다.

이후, 브라우저는 렌더 트리를 기반으로 각 요소의 위치와 크기를 계산합니다. 이를 통해 각 요소가 화면에 어디에 위치할지를 결정합니다.

그리고 계산된 스타일과 레이아웃 정보를 사용하여 실제로 화면에 픽셀을 그립니다. 이 과정에서 브라우저는 레이어를 생성하고, 이를 합성하여 최종 화면을 생성합니다.

마지막으로 생성된 레이어들이 합성되어 최종 화면이 사용자에게 표시됩니다.

위 과정이 기본적은 브라우저 렌더링의 과정이지만 최신 브라우저는 각자 최적화 기술이 사용되었기 때문에 실제로는 더 복잡한 과정이 진행됩니다.

## 🔗 꼬리질문: 브라우저의 종류가 다양한데 같은 렌더링 방식을 하는 걸까요? 다르다면 어떤점이 다를까요?

### 나라's 답변: <!-- 답변 -->

### 슬기's 답변: <!-- 답변 -->

### 정호's 답변: <!-- 답변 -->

다양한 브라우저 중 가장 많이 쓰이는 2가지 브라우저인 Chrome과 Safari를 비교하여 말씀드리겠습니다.
Chrome은 Blink를 Safari는 Webkit이라는 렌더링 엔진을 사용합니다. 렌더링 엔진은 웹 페이지를 해석하고 표시하는 역할을 하며
두 브라우저에서 모두 웹 표준을 준수하려고 노력하지만, CSS를 처리하는 세부적인 부분에서 차이가 나타납니다.
또한 Chrome은 V8 JavaScript 엔진을 사용하고 있고, 사파리는 Nitro (또는 JavaScriptCore) 엔진을 사용하고 있습니다.
이 엔진들은 성능 및 최적화 측면에서 차이가 있을 수 있습니다.

#### 🔗🔗 꼬리의 꼬리질문: 크롬과 사파리의 자바스크립트 엔진은 서로 다른 데 어떤 차이점이 있을까요?

##### 나라's 답변: <!-- 답변 -->

##### 슬기's 답변: <!-- 답변 -->

##### 정호's 답변: <!-- 답변 -->

Chrome은 V8 JavaScript 엔진을 사용합니다. V8 엔진은 주로 성능과 개방성에 중점을 둔 엔진입니다. 오픈 소스로 개발되었으며,
빠른 성능을 제공하기 위해 특히 Just-In-Time 컴파일레이션 기술을 사용합니다. 이는 JavaScript 코드를 런타임에서 기계에로 변환하여
더 빠른 실행을 가능하게 합니다.

사파리는 Nitro라는 JavaScript 엔진을 사용합니다. Nitro는 Apple의 생태계에 통합되도록 최적화되어 있습니다. 이는 Apple의 다양한 제품과
서비스 간의 시스템 상화 운용성을 향상시키기 위함이고, 또 Nitro는 성능 최적화와 메모리 효율성에 중점을 둡니다.

두 엔진을 간단하게 요약하자면 V8은 성능을 올리는 데 집중, Nitro는 최적화하는 데 집중하는 방향으로 발전하고 있습니다.

#### 🔗🔗 꼬리의 꼬리질문: 크롬과 사파리의 렌더링 엔진은 서로 다른 데 브라우저의 렌더링 과정에서 어떤 차이점 이 있나요?

##### 나라's 답변: <!-- 답변 -->

##### 슬기's 답변: <!-- 답변 -->

##### 정호's 답변: <!-- 답변 -->

Chrome은 Blink를 Safari는 Webkit이라는 렌더링 엔진을 사용합니다. 렌더링 엔진은 웹 페이지를 해석하고 표시하는 역할을 하며
두 브라우저에서 모두 웹 표준을 준수하려고 노력하지만, CSS를 처리하는 세부적인 부분에서 차이가 나타납니다.

## 🔗 꼬리질문: 주소창에 google.com을 작성했을 때 일어나는 과정을 설명해주세요

### 나라's 답변: <!-- 답변 -->

### 슬기's 답변: <!-- 답변 -->

### 정호's 답변: <!-- 답변 -->

먼저, 브라우저는 입력한 도메인을 IP 주소로 변환하기 위해 DNS 서버에 요청을 합니다.

그 후, 브라우저는 응답받은 IP주소를 사용하여 Google 서버에 TCP/IP 연결을 시도합니다.

그리고 브라우저는 서버에게 해당 도메인의 리소스를 요청하는 HTTP 요청을 보내며, Google 서버는 브라우저 요청에 대한 HTTP 응답을 생성하여 보냅니다. 이 응답에는 HTML 문서, CSS 스타일 시트, JavaScript 파일 등의 리소스가 포함됩니다.

Google 서버로부터 리소스를 받으면 브라우저는 받아온 HTML 문서를 해석하여 DOM (문서 객체 모델)을 생성합니다. 그리고 CSS파일 또는 스타일 요소의 스타일 정보를 가져와서 각 요소에 적용하고, 레이아웃을 계산합니다. 이 단계에서 요소들의 크기와 위치가 결정됩니다.

그리고 화면에 표시될 각 요소를 그리며 이 단계에서 픽셀 단위로 그림이 그려지는 과정이 이루어집니다.

마지막으로 그려진 요소들을 화면에 합성하여 최종 화면을 생성합니다. 이 과정은 GPU를 통해 이루어지며, 최적화를 위해 레이어를 합성하는 과정이 포함됩니다.

#### 🔗🔗 꼬리의 꼬리질문: DNS에 대해 설명해 주세요

##### 나라's 답변: <!-- 답변 -->

##### 슬기's 답변: <!-- 답변 -->

##### 정호's 답변: <!-- 답변 -->

DNS는 Domain Name System의 약자로 인터넷에서 사용되는 도메인 이름을 IP 주소로 변환하거나, 그 반대의 역할을 수행하는 시스템입니다.

#### 🔗🔗 꼬리의 꼬리의 꼬리질문: DNS서버에 문제가 생긴다면 페이지에 접속할 수 없을까요?

##### 나라's 답변: <!-- 답변 -->

##### 슬기's 답변: <!-- 답변 -->

##### 정호's 답변: <!-- 답변 -->

DNS 서버에 문제가 생긴다면 일반적인 방법으로는 페이지에 접속할 수 없습니다. 하지만 만약 사용자가 해당 페이지의 IP 주소를 알고 있다면 IP 주소를 직접 입력하여 접속할 수 있습니다.

#### 🔗🔗 꼬리의 꼬리의 꼬리질문: 한 번도 방문한 적이 없는 사이트에 방문할 때와 방금 방문 했던 사이트를 다시 방문하는 것의 차이점을 설명해주세요

##### 나라's 답변: <!-- 답변 -->

##### 슬기's 답변: <!-- 답변 -->

##### 정호's 답변: <!-- 답변 -->

한 번도 방문한 적이 없는 사이트에 방문할 경우 브라우저에서 입력한 도메인을 기준으로 DNS 서버에 요청을 보내고 IP 주소로 응답을 받습니다. 하지만 이미 방문 했던 사이트를 다시 방문하는 경우에는 DNS에서 지원하는 캐싱 기능이 발동됩니다.  
DNS는 반복적인 조회를 방지하고 응답 시간을 단축하기 위해 캐싱을 사용합니다. DNS 서버는 조회한 도메인에 대한 IP 주소를 일정 기간 동안 저장하고, 이후에 같은 도메인에 대한 조회가 있을 때는 캐시에서 응답을 제공합니다.

## 🔗 꼬리질문: 브라우저 렌더링 최적화 방법에 대해 설명해주세요.

### 나라's 답변: <!-- 답변 -->

### 슬기's 답변: <!-- 답변 -->

### 정호's 답변: <!-- 답변 -->

브라우저 렌더링을 최적화하는 방법 중에서 기본적인 것들을 설명드리겠습니다.

1. CSS와 JavaScript 최적화

- 미니파이 및 압축: CSS와 JavaScript 파일을 최소화하고 압축하여 파일 크기를 줄일 수 있습니다.
- 비동기 로딩: 페이지 로딩 중에 필요한 부분만 로드되도록 비동기적으로 스크립트를 로드할 수 있습니다.
- Critical CSS: 페이지 로딩에 필요한 초기 렌더링에 중요한 CSS를 식별하여 이 부분을 최적화할 수 있습니다.

2. 이미지 최적화

- 압축: 이미지를 최적화하고 손실 압축을 사용하여 파일 크기를 줄일 수 있습니다.
- 레이지 로딩: 페이지 스크롤 시에만 이미지를 로드하도록 설정하여 초기 페이지 로딩 속도를 향상 시킬 수 있습니다.

3. 서버 측 최적화

- 압축 및 브라우저 캐싱: 서버에서 전송되는 자원들을 Gzip등을 사용하여 압축하고, 브라우저 캐싱을 통해 자주 변경되지 않는 자원들을 저장할 수 있습니다.
- CDN 활용: 콘텐츠 전송 네트워크(CDN)을 사용하여 전 세계의 서버에 컨텐츠를 배포하고 로드 시간을 최적화할 수 있습니다.

4. 렌더링 성능 도구 사용

- 크롬 개발자 도구: 브라우저에서 제공하는 도구를 사용하여 렌더링 성능을 분석하여 최적화가 필요한 부분을 찾아 최적화할 수 있습니다.

#### 🔗🔗 꼬리의 꼬리질문: Reflow / Repaint 중에 어느 게 더 성능에 영향을 끼칠까요.

##### 나라's 답변: <!-- 답변 -->

##### 슬기's 답변: <!-- 답변 -->

##### 정호's 답변: <!-- 답변 -->

Reflow가 더 성능에 영향을 끼칩니다. Reflow는 레이아웃을 다시 계산하고 배치하는 과정을 말하며 요소가 변경되었을 때
해당 요소의 모든 하위 요소들의 크기와 위치를 계산하고 레이아웃을 다시 배치해야 되기 때문에 성능에 부하를 줄 수 있습니다.

#### 🔗🔗 꼬리의 꼬리질문: reflow를 피하거나 최소화하는 방식에 대해 설명해주세요.

##### 나라's 답변: <!-- 답변 -->

##### 슬기's 답변: <!-- 답변 -->

##### 정호's 답변: <!-- 답변 -->

가상 요소를 사용하여 특정 스타일을 적용할 수 있습니다. 가상 요소는 실제 DOM 요소를 생성하지 않으므로 Reflow가 발생하지 않습니다.

```
.myElement::before {
    content: '';
    display: block;
    width: 100px;
    height: 50px;
}
```

또한 배치 변경을 최소화 해야되기 때문에 transform 속성을 활용하여 이동하는 것이 좋습니다.

```
element.style.transform = 'translate(10px, 20px)';
```

## 🔗 꼬리질문: DOM과 CSSOM이 무엇인지 설명해주세요.

### 나라's 답변: <!-- 답변 -->

### 슬기's 답변: <!-- 답변 -->

### 정호's 답변: <!-- 답변 -->

DOM은 Document Object Model의 약자로 웹 페이지의 문서 구조를 나타내는 모델입니다. HTML 또는 XML 문서의 각 요소를 객체로 표현하고, 이들 객체 간의 관계를 나타내는 트리 구조를 형성합니다.

CSSOM은 CSS Object Model의 약자로 웹 페이지의 스타일 정보를 나타내는 모델로, CSS 규칙, 스타일 속성 및 값을 객체로 표현합니다.

두 모델은 각각 HTML 문서의 구조와 CSS 스타일을 추상화하고, 프로그래밍 언어를 통해 동적으로 조작할 수 있도록 합니다.

#### 🔗🔗 꼬리의 꼬리질문: link를 만날 때 CSSOM 트리가 만들어진다면 전처리기를 사용한다면 link태그는 어디에 작성될까요?

##### 나라's 답변: <!-- 답변 -->

##### 슬기's 답변: <!-- 답변 -->

##### 정호's 답변: <!-- 답변 -->

만약 Sass를 사용하여 아래와 같은 코드를 작성한다면

    .container{
        display: flex;
        justify-content: center;
        .block{
            width: 300px;
            height: 300px;
        }
    }

컴파일이 된 후 아래와 같은 css파일이 생성되며

    .container {
        display: flex;
        justify-content: center;
    }

    .container .block {
        width: 300px;
        height: 300px;
    }

HTML 파일의 head 부분에 link태그로 삽입됩니다.

    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" href="styles.css"> <!-- 여기에 추가 -->
        <title>Document</title>
    </head>
    <body>
    <!-- 내용 -->
    </body>
    </html>

#### 🔗🔗 꼬리의 꼬리질문: index.html을 읽어서 그려지는 과정을 설명해주세요.

##### 나라's 답변: <!-- 답변 -->

##### 슬기's 답변: <!-- 답변 -->

##### 정호's 답변: <!-- 답변 -->

첫 번째로 HTML 파싱을 진행하여 DOM 트리를 생성합니다. 그리고 HTML 파싱 중에 만나는
`<link>` 또는 `<style>` 태그를 통해 연결된 CSS 파일들이 로드됩니다. CSS 파일을 파싱하여 CSSOM 트리를 생성하고 DOM 트리와 CSSOM 트리를 결합하여 렌더 트리를 생성합니다.
이때 렌더 트리에는 실제로 화면에 표시되는 요소들만 초함하며, 보이지 않는 요소 display:none은 렌더 트리에 포함되지 않습니다.

만약 `<script>` 태그를 만났는데 defer 또는 async 속성을 지정하지 않은 경우 html 파싱을 일시 중단하고 스크립트를 로드하고 실행합니다.

그리고 렌더 트리의 각 요소에 대한 위치와 크기 등의 레이아웃 정보가 계산되어 브라우저 화면에 어떻게 배치될지 결정됩니다. 레이아웃이 결정된 후, 각 요소의 실제 픽셀을 그리는 과정이 진행됩니다. 이 과정을 페인트라고 하며, 이 단계에서 색상, 텍스트, 이미지 등이 화면에 페인트됩니다.

각 레이어의 페인팅이 완료되면, 레이어들이 합성되어 최종 화면이 생성됩니다.

#### 🔗🔗 꼬리의 꼬리질문: HTML 문서에서 스크립트와 스타일시트의 로딩 순서가 중요한 이유는 무엇인가요?

##### 나라's 답변: <!-- 답변 -->

##### 슬기's 답변: <!-- 답변 -->

##### 정호's 답변: <!-- 답변 -->

스크립트와 스타일시트의 로딩 순서는 웹 페이지의 동작과 외관에 직접적인 영향을 미치기 때문에 중요합니다.

2. 렌더링 차단 방지

- 브라우저는 HTML을 파싱하면서 스타일시트를 만나면 해당 스타일시트를 로드하기 위해 추가적인 네트워크 요청을 보냅니다. 만약 자바스크립트 코드가 스타일시트보다 먼저 로드된다면, 브라우저는 스타일이 적용되지 않은 상태에서 자바스크립트 코드를 실행할 수 있습니다.

#### 🔗🔗 꼬리의 꼬리질문: 자바스크립트 파일을 왜 비동기적으로 가져와야할까요?

##### 나라's 답변: <!-- 답변 -->

##### 슬기's 답변: <!-- 답변 -->

##### 정호's 답변: <!-- 답변 -->

자바스크립트 파일을 비동기적으로 가져와야하는 이유는 웹 페이지의 성능과 사용자 경험을 향상시키기 위함입니다.

1. 페이지 로딩 속도 향상

- 비동기적으로 스크립트를 가져오면 다른 자원들과 병렬로 다운로드될 수 있습니다. 이는 페이지 로딩 속도를 향상시키고, 사용자는 더 빠르게 웹 페이지를 확인할 수 있습니다.

2. 브라우저 차단 방지

- 동기적으로 스크립트를 가져오면 해당 스크립트가 다운로드되는 동안 브라우저는 다른 작업을 수행할 수 없습니다. 비동기적으로 스크립트를 가져오면 다운로드는 백그라운드에서 진행되기 때문에 브라우저가 차단되지 않습니다.

3. 동적 로딩 및 성능 최적화

- 일부 상황에서는 특정 조건이나 사용자 상호작용에 따라 스크립트를 동적으로 로딩해야 할 수 있습니다. 비동기적으로 스크립트를 로딩하면 필요한 시점에 필요한 스크립트를 로드할 수 있습니다.

4. 캐싱을 통한 성능 향상

- 비동기적으로 스크립트를 가져올 때 브라우저는 캐싱을 활용할 수 있습니다. 이미 다운로드한 스크립트는 브라우저 캐시에 저장되어 다음 방문 시에는 다시 다운로드하지 않아도 되므로 성능이 향상됩니다.

5. 오류 처리와 로드 순서

- 비동기적으로 스크립트를 가져오면 스크립트 로딩 중에 발생하는 오류를 브라우저가 감지하고 적절히 처리할 수 있습니다. 또한, 다양한 스크립트들이 병렬로 로드되므로 로딩 순서에 대한 제어가 가능합니다.

#### 🔗🔗 꼬리의 꼬리질문: defer와 async에 대해서 설명해주세요

##### 나라's 답변: <!-- 답변 -->

##### 슬기's 답변: <!-- 답변 -->

##### 정호's 답변: <!-- 답변 -->

defer과 async는 `<script>` 태그의 속성으로, 자바스크립트 파일을 비동기적으로 가져올 때의 동작을 제어하는 데 사용됩니다.

1. async

- async 속성은 스크립트를 비동기적으로 다운로드하고, 다운로드가 완료되면 즉시 실행합니다. 이때 다운로드와 실행은 다른 스크립트 파일 간에 상호 의존성이 없을 때 유용합니다.
- 페이지 로딩 중에 스크립트를 병렬로 다운로드하고 실행하기 때문에, 다운로드가 먼저 완료되는 스크립트가 먼저 실행됩니다.

2. defer

- defer 속성은 스크립트를 비동기적으로 다운로드하지만, 페이지 파싱이 완료된 후에 실행합니다. 이는 스크립트 실행이 페이지 렌더링을 방해하지 않도록 보장합니다.
- 여러 개의 defer 스크립트가 있다면, 순서대로 실행됩니다.

두 차이점을 간단히 요약하자면 async는 다운로드 완료와 상관없이 스크립트를 실행하므로, 다운로드 순서와 실행 순서가 일치하지 않을 수 있습니다. 하지만 defer는 다운로드는 비동기적으로 진행되지만, 실행은 페이지 파싱이 완료된 후에 이루어지므로 다운로드 순서와 실행 순서가 보장됩니다.

상호 의존성이 없는 독립적인 스크립트는 async를 사용하고, 페이지 파싱 후 실행이 필요한 스크립트는 defer를 사용해야합니다.

## 🔗 꼬리질문: Critical Rendering Path에 대해서 설명해주세요

### 나라's 답변: <!-- 답변 -->

### 슬기's 답변: <!-- 답변 -->

### 정호's 답변: <!-- 답변 -->

Critical Rendering Path는 브라우저가 웹 페이지를 렌더링하는 과정 중에서 가장 중요한 단계들의 시퀀스를 의미합니다. 이 경로를 최적화함으로써 웹 페이지의 로딩 속도를 향상시킬 수 있습니다.

Critical Rendering Path는 다음과 같은 단계로 구성됩니다.

1. HTML 파싱과 DOM 트리 구축

2. CSS 파싱과 스타일 계산

3. 레이아웃

4. 페인팅과 렌더링

## 🔗 꼬리질문: 웹사이트 초기 로딩 속도를 향상시키기 위한 주요 전략은 무엇인가요?

### 나라's 답변: <!-- 답변 -->

### 슬기's 답변: <!-- 답변 -->

### 정호's 답변: <!-- 답변 -->

웹 사이트 초기 로딩 속도를 향상시키기 위한 주요 전략은 아래와 같습니다.

1. 이미지 최적화:

이미지는 웹 페이지의 주요 자원 중 하나이며, 최적화를 통해 파일 크기를 줄이고 필요한 크기로 자르는 등의 작업을 수행할 수 있습니다. 이미지 포맷 선택과 압축 기술을 사용하여 최적화를 진행할 수 있습니다.

2. CSS 및 JavaScript 최적화

CSS와 JavaScript 파일을 최소화(Minification)하여 불필요한 공백과 주석을 제거하고, 필요한 경우 파일을 압축, 중복된 코드를 제거하고, 사용되지 않는 코드를 최소화하여 최적화를 진행할 수 있습니다.

3. 브라우저 캐싱 활용

정적 리소스에 대한 브라우저 캐싱을 통해 이미 다운로드한 리소스를 캐시에 저장하여 재사용할 수 있습니다. 이를 통해 다운로드 시간을 절약하고 성능을 향상시킬 수 있습니다.

4. 파이프라이닝 및 병렬 다운로드

HTTP 파이프라이닝을 통해 여러 리소스 요청을 동시에 처리하고, 동시에 다운로드되는 리소스 수를 최대화하여 전체 로딩 시간을 단축하세요.

5. 지연 로딩(Lazy Loading)

페이지에 필요하지 않은 리소스를 초기에 모두 로드하는 대신, 필요한 시점에 로드하도록 지연 로딩을 사용하세요. 특히 이미지나 동영상 등의 큰 미디어 자원에 대해서는 지연 로딩이 효과적입니다.

6. 요청 수 최소화

도메인 샤딩(Domain Sharding)을 피하고, 요청 수를 최소화하여 네트워크 비용을 줄이세요. CSS 스프라이트, 데이터 URI 등을 사용하여 여러 이미지를 하나의 요청으로 통합할 수 있습니다.

7. CDN 활용:

콘텐츠 전송 네트워크(CDN)를 활용하여 웹 페이지의 정적 리소스를 여러 서버에 분산 저장하여 사용자에게 가까운 위치에서 빠르게 제공할 수 있도록 하세요.

8. 서버 사이드 렌더링(SSR) 및 정적 사이트 생성(SSG)

SSR과 SSG를 통해 초기 로딩 속도를 향상시킬 수 있습니다. 서버에서 페이지를 렌더링하거나 사전에 정적인 페이지를 생성하여 사용자에게 빠르게 제공합니다.

#### 🔗🔗 꼬리의 꼬리질문: 웹페이지가 로드될 때 이미지 최적화의 중요성과 그 방법에 대해 설명해주세요.

##### 나라's 답변: <!-- 답변 -->

##### 슬기's 답변: <!-- 답변 -->

##### 정호's 답변: <!-- 답변 -->

웹페이지에서 이미지 최적화는 매우 중요한 요소 중 하나입니다. 이미지 최적화를 통해 웹페이지의 로딩 속도를 향상시키고 대역폭을 절약할 수 있으며, 이는 사용자 경험을 향상시키는 데 기여합니다.

이미지 최적화 방법은 아래와 같습니다.

1. 이미지 포맷 선택: 이미지 포맷은 특정한 상황에 적합합니다. JPEG는 사진에 PNG는 투명 이미지에, WenP는 최신 브라우저에서 효과적입니다.

2. 이미지 해상도 조정: 필요 이상으로 큰 해상도의 이미지를 사용하지 않도록 주의합니다. 스크린의 크기에 맞게 이미지를 조정하고, 반응형 디자인을 위해 여러 크기의 이미지를 제공하는 것이 좋습니다.

3. 이미지 압축: 이미지를 압축하여 파일 크기를 줄입니다. 압축 도구나 온라인 서비스를 사용하거나, 빌드 도구를 통해 자동으로 압축할 수 있습니다.

4. 지연 로딩: 지연 로딩을 통해 페이지 로딩 시에 필요한 이미지만 로드하고, 나머지는 사용자가 스크롤할 때 로딩하도록 지연시킬 수 있습니다.

5. CSS 스프라이트: 여러 이미지를 하나의 이미지로 결합하여 스프라이트로 만들면, 여러 요청을 하나로 줄일 수 있습니다.

6. 이미지 캐싱 활용: 이미지를 적절히 캐싱하여 요청을 최소화하고, 사용자가 이전에 방믄훈 페이지의 이미리즐 더 빠르게 로드할 수 있습니다.

## 🔗 꼬리질문: Virtual DOM은 무엇이며, 이를 사용하는 이유는 무엇인가요?

### 나라's 답변: <!-- 답변 -->

### 슬기's 답변: <!-- 답변 -->

### 정호's 답변: <!-- 답변 -->

Virtual DOM은 실제 DOM의 가상 복제본입니다. 웹 애플리케이션에서 UI를 효율적으로 업데이트하는 데 사용됩니다. 일반적으로는 React와 같은 라이브러리나 프레임워크에서 사용됩니다.

이것을 사용하는 이유 중 하나는 성능 향상입니다. 실제 DOM 조작은 비용이 많이 들 수 있습니다. 업데이트가 발생할 때마다 브라우저는 실제 DOM을 다시 그리고 레이아웃을 계산하며 리페인팅을 수행해야 합니다. 이는 성능을 저하시킬 수 있습니다.

하지만 Virtual DOM은 이러한 문제를 완화하기 위해 가상의 복제본을 메모리에서 유지합니다. 변경 사항이 발생하면 이 가상 DOM에서 변경 사항을 실제 DOM으로 전파하기 전에 비교 알고리즘을 사용하여 최소한의 업데이트만 수행합니다.

또한 Virtual DOM은 개발자가에게 더 직관적인 개발 경험을 제공합니다. 전체 UI를 직접 조작하는 대신 상태를 업데이트 하고 React나 Vue 같은 라이브러리가 알아서 업데이트를 처리합니다.

## 🔗 꼬리질문: 웹 페이지의 렌더링 성능을 측정하기 위한 도구나 방법은 무엇이 있나요?

### 나라's 답변: <!-- 답변 -->

### 슬기's 답변: <!-- 답변 -->

### 정호's 답변: <!-- 답변 -->

Google Chrome 개발자 도구에 있는 Performance 탭을 통해 렌더링 성능을 측정할 수 있습니다. 이 탭에서는 CPU 사용량, 메모리 사용량, 네트워크 활동 등을 실시간으로 모니터링할 수 있습니다.

또한 Lighthouse 탭은 웹 앱의 품질을 평가하는 데 사용됩니다. 성능, 접근성, SEO 등 다양한 측면에서 평가를 제공하며, 특히 웹페이지의 성능을 향상시키는 데 도움을 줍니다.

이 밖에도 성능 측정을 도와주는 웹 사이트나 다양한 Third-party 라이브러리를 통해 성능을 측정할 수 있습니다. (React Dev Tools)

## 🔗 꼬리질문: 브라우저의 렌더링과 관련하여 GPU가 하는 역할은 무엇인가요?

### 나라's 답변: <!-- 답변 -->

### 슬기's 답변: <!-- 답변 -->

### 정호's 답변: <!-- 답변 -->

브라우저는 화면에 표시할 요소들을 그린 후, 이를 합성하여 최종 화면을 생성랍니다. GPU는 이러한 페인팅과 합성 작업을 가속화하여 렌더링 성능을 향상시킵니다. 또한 CSS 3D 변환 및 애니메이션과 같은 그래픽 작업을 가속화하는 데 사용되며, 웹 페이지의 스크롤 및 줌 기능을 부드럽게 처리하거나 canvas 태그를 사용해서 그래픽을 그릴 때 해당 작업을 가속화하는 데 사용됩니다.

## 🔗 꼬리질문: 웹 워커(Web Workers)에 대해 설명하고, 이것이 렌더링 성능에 어떻게 도움을 주는지 설명해주세요.

### 나라's 답변: <!-- 답변 -->

### 슬기's 답변: <!-- 답변 -->

### 정호's 답변: <!-- 답변 -->

웹 워커는 웹 애플리케이션에서 백그라운드에서 동작하는 스크립트를 실행하는 데 사용되는 기술입니다. 기본적으로 JavaScrit는 싱글 스레드에서 동작하지만, 웹 워커를 통해 여러 작업을 병렬로 처리할 수 있습니다.

웹 워커의 주요 특징과 도움을 주는 방식에 대해 설명드리겠습니다.

1. 별도의 스레드

- 웹 워커는 메인 스레드와 별도의 스레드에서 동작하므로 메인 스레드의 렌더링 및 사용자 인터렉션에 영향을 주지 않고 백그라운드에서 계산 작업이나 데이터 가공 등을 수행할 수 있습니다.

2. 렌더링 블로킹 방지

- 복작한 계산 또는 대량의 데이터 처리는 메인 스레드에서 수행하면 렌더링을 차단할 수 있습니다. 웹 워커를 사용하면 이러한 계산을 백그라운드에서 수행하고, 메인 스레드는 렌더링에 집중할 수 있습니다.

3. 데이터 차리와 네트워크 요청

- 대용량 데이터 처리나 복잡한 알고리즘 실행은 웹 워커를 통해 효율적으로 처리할 수 있습니다. 또한, 웹 워커는 메인 스레드와 별개로 네트워크 요청을 처리할 수 있어, 데이터를 백그라운드에서 미리 가져오고 메인 스레드에서는 렌더링에 집중할 수 있습니다.

4. 성능 향상 및 반응성 개선

- 웹 워커를 사용하면 병렬 처리를 통해 전반적인 성능을 향상시킬 수 있습니다. 특히 대규모 데이터 처리나 복잡한 계산이 필요한 작업에서 웹 워커를 활용하면 애플리케이션의 반응성을 향상시킬 수 있습니다.

간단히 요약하자면 웹 워커는 메인 스레드와 별도의 스레드에서 동작하므로 대용량 데이터 처리 또는 알고리즘 실행 같은 시간이 오래 걸리는 작업을 맡아서 진행하고 메인 스레드에서는 렌더링 작업에 집중하여 성능을 최적화할 수 있습니다.
