# 📆 날짜: 2023-10-09

## 🎯 공통 질문: 브라우저의 렌더링 과정을 순서대로 상세하게 설명해주세요.

### 나라's 답변: 브라우저에서 서버에 렌더링에 필요한 요소를 요청한 다음 HTML파일을 파싱한 다음 DOM트리를 생성, CSS파일을 파싱하여 CSSOM트리를 생성합니다. 두가지의 트리를 토대로 노드로 구성된 렌더트리를 생성하여 해당 노드가 위치와 크기를 계산하는 레이아웃단계를 거칩니다. 이후 계산이 완료된다면 화면에 요소를 그리는 페인트 단계를 진행하고 이후 Composite단계로 각 레이어들을 합쳐 화면에 렌더링 됩니다.

### 슬기's 답변: 브라우저에 문서가 로딩됨에따라 HTML 태그를 파싱하여 DOM트리를 생성하고, CSS파일로 CSSOM 트리를 생성합니다. 이 트리들로 실제 화면에 표시될 노드들로 구성된 렌더트리를 생성하며 이 렌더트리를 기반으로 각 노드가 화면에 어디에 어떻게 위치할지 계산하는 레이아웃단계를 거쳐 실제 화면에 그려지는 페인트단계로 가게됩니다. 이후 composite 단계로 레이어를 합성하여 최종적으로 화면에 렌더링합니다.

### 정호's 답변: <!-- 답변 -->

#### 🔗🔗 슬기's 꼬리의 꼬리의 꼬리질문: DOM트리와 렌더트리의 차이는 무엇인가요?

##### 슬기's 답변: DOM트리의 경우 HTML 태그를 파싱하여 노드들로 DOM 트리를 생성하지만, 렌더트리의 경우 실제 브라우저에 보여줄 필요한 노드들로만 구성됩니다. 예를들자면 Head 태그 혹은 display:none 과같은 속성들이 포함된 노드들은 포함되지않는 차이점이 있습니다.

## 🔗 꼬리질문: 브라우저의 종류가 다양한데 같은 렌더링 방식을 하는 걸까요? 다르다면 어떤점이 다를까요?

### 나라's 답변: 브라우저 종류는 크롬, 사파리, 파이어폭스 등이 존재하며 이는 제각기 다른 렌더링 엔진을 가지고 있습니다. 대표적으로 크롬은 현재 Blink, 사파리는 webkit을 사용하고 있으며 각 엔진마다 더 빠르게 렌더링 하는 특징, 아님 특정 요소를 렌더링하는 특징이 있습니다.

### 슬기's 답변: 각각의 고유한 렌더링 엔진을 사용하기에 내부적인 렌더링 방식에는 차이가있습니다. 대부분의 브라우저들은 기본적인 렌더링프로세스는 비슷하게 진행되지만, 최적화방식, 데브툴즈와 같은 외부도구 제공등의 차이가 있습니다.

### 정호's 답변: <!-- 답변 -->

#### 🔗🔗 꼬리의 꼬리질문: 크롬과 사파리의 렌더링 엔진은 서로 다른 데 브라우저의 렌더링 과정에서 어떤 차이점 이 있나요?

##### 나라's 답변: 원래는 두 브라우저는 Webkit을 사용해왔지만 시간이 지나며 크롬은 Blink를 개발하여 현재 Blink를 사용하고 있습니다. 두 엔지는 내부적인 알고리즘의 차이가 있을 수 있으며 세부적인 처리에 있어서 차이점이 있습니다.

##### 슬기's 답변: 사파리의 경우 WebKit, 크롬의 경우 WebKit에서 파생된 Blink 를 사용하기에 렌더링 엔진이 다르지만 큰 프로세스는 비슷하게 동작하며 최적화와 같은 내부적인 동작 에서 차이가 있을 수 있습니다.

##### 정호's 답변: <!-- 답변 -->

## 🔗 꼬리질문: 주소창에 google.com을 작성했을 때 일어나는 과정을 설명해주세요

### 나라's 답변: 우선 도메인 이름에 해당하는 google.com을 DNS서버에서 검색을 실시합니다. 이후 가까운 DNS서버에서 도메인이름(google.com)에 해당하는 IP주소를 찾아 URL정보와 함께 전달을 합니다. 이후 전달받은 IP주소를 토대로 브라우저는 서버에게 html문서를 HTTP요청 메세지를 전송합니다. 서버는 정적인 파일을 WAS에서는 동적인 파일을 처리하여 브라우저에 전송합니다. 브라우저는 서버의 응답 리소스로 Critical Rendering Path단계를 거치며 페이지에 내용을 렌더링합니다.

### 슬기's 답변: 먼저 브라우저는 로컬캐시를 확인하여 google.com의 IP주소를 확인해보고 없다면 DNS에 IP주소를 요청합니다. DNS로부터 받은 IP주소로 TCP연결을 시도하고 HTTP 프로토콜을 통해 웹 페이지를 요청합니다. 웹페이지로부터 받은 파일들로부터 파싱하여 DOM, CSSOM트리를 만들고 만들어진 트리를 바탕으로 렌더트리를 생성하게됩니다. 이후 자바스크립트 파일을만나게되면 자바스크립트 파일을 로드하고 실행하며 렌더트리를 기반으로 웹 페이지를 화면에 렌더링됩니다.

### 정호's 답변: <!-- 답변 -->

#### 🔗🔗 꼬리의 꼬리질문: DNS에 대해 설명해 주세요

##### 나라's 답변: 컴퓨터는 인간의 언어를 읽을 수 없기때문에 Domain Name System라는 시스템을 사용하여 전달받은 도메인 이름(google.com)을 IP주소로 변환해줍니다.

##### 슬기's 답변: DNS(Domain Name System)은 인터넷 상의 도메인 이름을 IP 주소로 변환하거나 그 반대의 작업을 수행하는 시스템입니다.

##### 정호's 답변: <!-- 답변 -->

#### 🔗🔗 꼬리의 꼬리의 꼬리질문: DNS서버에 문제가 생긴다면 페이지에 접속할 수 없을까요?

##### 나라's 답변: DNS서버는 도메인 이름으로 넘어온 값을 IP주소로 변환해주는 역할로써 만약 DNS서버에 문제가 생긴다면 IP주소로 변환하는 것이 불가능하기에 웹 사이트에 접속할 수 없다고 생각됩니다. 하지만 IP주소를 알고있다면 해당 IP주소로 접속은 가능할 것이라고 생각됩니다.

##### 슬기's 답변: 만약 DNS 서버에 문제가 발생하면 해당 URL의 IP 주소를 알아내는 것이 어려워져 웹페이지에 접근이 어렵게 됩니다. 하지만, IP주소를 알고있다면 직접 IP주소를 입력하여 접속할 수 있습니다.

##### 정호's 답변: <!-- 답변 -->

#### 🔗🔗 꼬리의 꼬리의 꼬리질문: 한 번도 방문한 적이 없는 사이트에 방문할 때와 방금 방문 했던 사이트를 다시 방문하는 것의 차이점을 설명해주세요

##### 나라's 답변: 한 번도 방문한 적이 없는 사이트에는 IP주소로 변화하는 시간과, HTTP요청, 리소스 다운, 페이지 렌더링을 해야하지만 한번 방문을 했다면 이전 정보들을 로컬 캐시에 저장되어 있을 수 있기에 DNS조회, HTTP요청이 줄어 들 수 있습니다. 또한 리소스를 다운하는 과정에도 브라우저 캐시에 남아 있을 가능성이 있기때문에 다시 로드 할 필요가 없습니다. 또한 페이지를 렌더링을 하는 과정도 단축할 수 있습니다.

##### 슬기's 답변: 처음 방문한 사이트는 DNS에 해당 사이트의 IP주소를 요청하는 작업을 거치게됩니다. 반면, 한번 방문한 사이트는 로컬 네트워크에 DNS 정보가 캐시되어있기에 DNS에 IP주소를 요청하는 작업을 생략하게되어 좀 더 빠르게 렌더링 될 수 있습니다.

##### 정호's 답변: <!-- 답변 -->

## 🔗 꼬리질문: 브라우저 렌더링 최적화 방법에 대해 설명해주세요.

### 나라's 답변: CSS나 JS파일을 압축하거나 이미지 크기를 줄여 리소스를 다운하는 시간을 단축시킵니다. 또한 JS파일을 비동기적으로 로딩하게하여 렌더링 시간을 중복되게 하지 않는 방법도 있습니다. 브라우저 캐시를 활용하여 변경이 적은 요소들을 브라우저 캐싱을 하여 로딩시간을 줄이는 방법, 최대한 DOM변경을 줄여 리플로우 횟수를 줄입니다.

### 슬기's 답변: 브라우저는 사용자에게 부드러운 웹 경험을 제공하기위해 1초당 60프레임의 렌더링을 목표로 합니다. 즉 1프레임당 10ms 이내로 최적화 하는 것이 필요합니다. 최적화방식에는 reflow, repaint를 최소화 하는 방식, 적절한 이미지 포맷을 선택하는 방식 혹은 코드 최적화 하는 방식으로 리소스를 최적화 하는 방식이 있으며, 혹은 레이지 로딩, requestAnimationFrame을 사용하여 애니메이션을 최적화하는 방식이있습니다.

### 정호's 답변: <!-- 답변 -->

#### 🔗🔗 꼬리의 꼬리질문: Reflow / Repaint 중에 어느 게 더 성능에 영향을 끼칠까요.

##### 나라's 답변: Reflow라고 생각합니다. Reflow는 변경사항을 반영하기위해 렌더트리를 재생성해야하며 이과정에서 크기나 위치를 계산하는 과정이 존재한다면 그만큼의 시간이 더 소요됩니다.

##### 슬기's 답변: Reflow는 요소의 레이아웃을 다시 계산하고 그에 따라 다른 요소들의 레이아웃도 다시 계산해야 할 가능성이 있으므로, Repaint보다 더 많은 계산이 필요하며 성능에 더 큰 영향을 미칩니다.

##### 정호's 답변: <!-- 답변 -->

#### 🔗🔗 꼬리의 꼬리질문: reflow를 피하거나 최소화하는 방식에 대해 설명해주세요.

##### 나라's 답변: CSS속성값을 미리 계산하는 방법, flexbox or grid레이아웃을 사용, lazy loading을 통한 필요한 페이지 로드 등이 있습니다.

##### 슬기's 답변: 간단하게는, 인라인 스타일을 피하며 CSS 클래스를 사용하고, 사용하지않는 노드의 경우 visibility: invisible 보다 display:none을 사용하여 렌더트리를만들지 않는 방식이 있습니다. 또한 여러번 연산을 필요로하는 작업은 requestAnimationFrame 을 사용하여 reflow를 줄일 수 있습니다.

##### 정호's 답변: <!-- 답변 -->

## 🔗 꼬리질문: DOM과 CSSOM이 무엇인지 설명해주세요.

### 나라's 답변: DOM(Document Object Model)은 웹페이지의 구조를 표현하는 것으로 HTML또는 XML로 표현됩니다. 문서구조를 트리형태로 나타내어지며 문서의 요소, 속성, 텍스트를 나타냅니다. 브라우저는 이 DOM구조를 사용하여 조작하거나 렌더링을 진행합니다. CSSOM(CSS Object Model) 로써 DOM과 유사하게 트리구조로 정보를 나타냅니다. 이는 브라우저 렌더링 엔진이 페이지를 스타일링하기위해 사용되어지며 JS를 통해 동적으로 저작이 가능합니다. DOM과 CSSOM을 결합하여 렌더트리를 만들며 렌더트리는 페이지의 표현을 위해 필요한 모든 노드를 포함합니다.

### 슬기's 답변: HTML 태그를 파싱하여 노드들로 구성된 Document Object Model 을 구성하고, CSS 파일을 파싱하여 스타일과 관련된 정보를 포함하는 트리구조로 CSS Object Model을 구성합니다.

### 정호's 답변: <!-- 답변 -->

#### 🔗🔗 꼬리의 꼬리질문: link를 만날 때 CSSOM 트리가 만들어진다면 전처리기를 사용한다면 CSSOM트리를 만드는 과정이 달라질까요?

##### 나라's 답변: 전처리기를 사용하더라도 전처리기를 활용하여 작성된 스타일 코드를 컴파일 하는 과정이 추가될 뿐이지 CSSOM트리를 구축하는 과정에서는 다를 점이 없다고 생각합니다.

##### 슬기's 답변: Sass와 같은 전처리기를 사용한다면 브라우저에서 바로 인식 및 해석이 불가합니다. 컴파일 과정을 거쳐 일반적인 css 파일로 변환되며 link태그를 통해 html문서에 포함되게 됩니다.

##### 정호's 답변: <!-- 답변 -->

#### 🔗🔗 꼬리의 꼬리질문: index.html을 읽어서 그려지는 과정을 설명해주세요.

##### 나라's 답변: 우선 index.html파일을 파싱하며 DOM트리를 생성합니다. 이때 HTML파일의 원시 바이트를 읽으며 인코딩을 거쳐 문자로 변환합니다. 이후 변환된 문자열을 토큰으로 변환합니다. 만들어진 토큰은 객체로 변환되며 이 객체를 마크업에 작성된 관계를 토대로 트리구조로 연결됩니다.

##### 슬기's 답변: 브라우저는 index.html파일을 서버에 요청하고 서버는 해당 파일을 응답으로 보냅니다. 이후 html 파일을 파싱 하고 DOM트리를 생성, link태그로 연결된 css파일이 있다면 CSSOM 트리를 생성하여 최종적으로 렌더트리를 생성하여 레이아웃 페인트의 과정을 거치게됩니다. (중복)

##### 정호's 답변: <!-- 답변 -->

#### 🔗🔗 꼬리의 꼬리질문: HTML 문서에서 스크립트와 스타일시트의 로딩 순서가 중요한 이유는 무엇인가요?

##### 나라's 답변: 스크립트 파일은 브라우저를 동적으로 변환하기 때문에 스크립트를 먼저 파싱한 후 스타일을 파싱한다면 구조를 변환하고 이후 스타일이 렌더링되기 때문에 의도한 동적인 변화를 기대하기 어렵습니다. 또한 로딩 순서를 지키지 않는다면 스타일이나 동적인 움직임이 적용된 컨텐츠가 유저에게 빠르게 제공되지 않기에 유저 경험을 저하시키는 이슈가 발생할 수 있습니다.

##### 슬기's 답변: html 파싱중 스크립트 태그를 만나면 파싱을 즉시 멈추고 스크립트 태그를 읽고 실행하기 때문입니다. 그렇게되면 스타일 파일을 불러오지않은상태에서 스크립트가 실행되어 사용자는 깨진 스타일을 먼저 볼 수 있기 때문에 로딩 순서가 중요합니다.

##### 정호's 답변: <!-- 답변 -->

#### 🔗🔗 꼬리의 꼬리질문: 자바스크립트 파일을 왜 비동기적으로 가져와야할까요?

##### 나라's 답변: JavaScript를 로딩은 HTML파싱과정을 중단시키고 진행하기 때문에 스크립트 파일이 완전한 로드되지 않는다면 DOM트리 생성이 늦어지며 이는 렌더트리 생성 즉, 페이지 로딩시간이 길어짐에 직결됩니다. 이러한 이유로 자바스크립트 파일을 비동기적으로 로딩한다면 더이상 로딩완료를 기다리지않고 페이지를 렌더할 수 있습니다.

##### 슬기's 답변: 위의 질문과 중복질문

##### 정호's 답변: <!-- 답변 -->

#### 🔗🔗 꼬리의 꼬리질문: defer와 async에 대해서 설명해주세요

##### 나라's 답변: 두 요소 다 스크립트 파일을 비동기적으로 로드해줍니다. async요소를 스크립트 태그에 적용하다면 스크립트 파일의 로딩이 완료된다면 HTML파싱을 멈추고 스크립트를 실행시킵니다. defer는 HTML파싱이 완료되고난 후 스크립트를 실행시킵니다.

##### 슬기's 답변: async 와 defer의 속성을 활용하여 스크립트의 로딩 및 실행순서를 제어할 수 있습니다. async 속성을 사용하면 스크립트는 병렬적으로 다운로드되며 만약 스크립트가 다운이완료되면 Html파싱이 중지되고 스크립트가 실행됩니다. defer 속성을 사용하면 병렬적으로 다운로드되나 Html파싱이 차단되지않으며 html파싱이 완료된 후 스크립트가 실행됩니다.

##### 정호's 답변: <!-- 답변 -->

#### 🔗🔗 슬기's 꼬리의 꼬리의 꼬리질문:

##### 슬기's 답변: 광고 스크립트의 경우 주 콘텐츠와 독립적이기에 스크립틀가 준비되는 즉시 광고를 로드하고 싶은 경우 async를 사용할 수 있고, 여러 스크립트 파일이 서로 의존성을가져 순서대로 로드되어야할 경우 defer를 사용할 수 있습니다.

## 🔗 꼬리질문: Critical Rendering Path에 대해서 설명해주세요

### 나라's 답변: 리소스를 처리하고 렌더링 하는 과정을 말하며 HTML, CSS파일을 로딩 및 파싱을하여 DOM, CSSOM트리를 생성 후 렌더트리를 생성하고 이를 통해 레이아웃을 계산후 페인팅하는 과정을 말합니다.

### 슬기's 답변: 중복질문

### 정호's 답변: <!-- 답변 -->

## 🔗 꼬리질문: 웹사이트 초기 로딩 속도를 향상시키기 위한 주요 전략은 무엇인가요?

### 나라's 답변: 리소스파일 크기를 줄이거나 이미지를 최적화하여 로딩속도를 향상시키는 방법, 스크립트 파일을 비동기로 로딩시키거나 코드분할을 통해 필요시점에만 로드시키는 방식 등이 있습니다.

### 슬기's 답변: 이미지최적화 혹은 웹폰트를 최적화 하는 방식과 같은 리소스를 최적화 하는 방식 혹은, css 와 js 비동기 로딩을 통해 최적화 하는 방법이 있습니다. 혹은 SSR을 사용하여 초기 로딩 속도를 향상 시킬 수 있습니다.

### 정호's 답변: <!-- 답변 -->

#### 🔗🔗 꼬리의 꼬리질문: 웹페이지가 로드될 때 이미지 최적화의 중요성과 그 방법에 대해 설명해주세요.

##### 나라's 답변: 이미지 최적화를 통해 로딩시간을 줄여 빠르게 유저에게 컨텐츠를 제공해 줍니다. 또한 이런 최적화를 한다면 SEO순위를 높게 결정되어 검색에서 유의미한 결과를 반환할 수 있습니다. 방법은 브라우저가 지원하는 이미지 포맷을 설정하거나 Lazy loading, image사이즈를 조절하는 툴을 사용할 수 있습니다.

##### 슬기's 답변: 최적화된 이미지는 더 빠르게 로드될 수 있으며 데이터 사용량을 절약할 수 있어 서버 부하 또한 감소할 수 있으며 SEO를 향상시키는 요소 중 하나입니다. 방법에는 적절한 포맷을 사용하기, 압축하기, 레이지로딩, CSS 스프라이트 방식 을 사용할 수 있습니다.

##### 정호's 답변: <!-- 답변 -->

## 🔗 꼬리질문: Virtual DOM은 무엇이며, 이를 사용하는 이유는 무엇인가요?

### 나라's 답변: 말 그대로 가상의 DOM이며 변경사항을 빠르게 파악하고 반영하기 위해 React에서 채택한 기술입니다. Virtual DOM은 사용자가 사용할 때마다 실제 DOM을 조작하는 방법이 성능저하를 일으키는 것을 해결하고자 나온 기술이며 Virtual DOM을 사용한다면 실제 DOM을 조작하는 것이 아닌 가상의 돔을 메모리 안에서 처리하여 변경된 부분만 실제DOM에 반영하여 렌더링 효율을 높힙니다.

### 슬기's 답변: 리액트와 같은 라이브러리의 경우 가상돔으로 실제 돔과 동일하게 복제를 한 가상돔을 만듭니다. 변화가 일어났을 경우 기존의 DOM과 가상DOM의 차이가 있는 것을 확인하여 변화된 부분만을 업데이트하기에 직접 DOM을 조작하는 것이아니기에 성능이 향상될 수 있습니다.

### 정호's 답변: <!-- 답변 -->

## 🔗 꼬리질문: 웹 페이지의 렌더링 성능을 측정하기 위한 도구나 방법은 무엇이 있나요?

### 나라's 답변: 크롬에서의 개발자도구중 Performence탭에서 로딩과 런타임 성능을 볼 수 있으며 WebPageTest나 Lighthouse와 같은 도구를 사용합니다. Performence탭에서 First Contentful Paint, Largest Contentful Paint, Total Blocking Time, Time to Interactive등의 지표를 확인하여 성능을 측정할 수 있습니다.

- FCP : 컨텐츠가 화면에 렌더링되는 시점
- LCP : 가장 큰 컨텐츠가 화면에 렌더링되는 시점
- TTI : 페이지가 완전한 인터렉티브가 되는 시간
- CLS : 페이지의 레이아웃이 자주 변경되는 지 측정하는 지표

### 슬기's 답변: 여러 도구가 있지만, 주로 사용하는 것은 크롬의 개발자 도구의 Performance탭이며 시각적으로 확인이 가능하여 주로 사용하며, 사용해보지는 않았지만 Lighthouse를 이용하면 성능지표와 최적화 제안도 제공한다고 알 고 있습니다.

### 정호's 답변: <!-- 답변 -->

## 🔗 꼬리질문: 브라우저의 렌더링과 관련하여 GPU가 하는 역할은 무엇인가요?

### 나라's 답변: 스타일링에서 애니메이션이나 트렌지션과 같은 효과를 렌더링 하는데 사용되며 canvas처럼 화면에 그래픽을 렌더링할 때 사용됩니다.

### 슬기's 답변: 복잡한 그래픽처리 혹은 애니메이션과 관련된 작업에서 GPU는 병렬 처리능력이 뛰어나기에 특정 그래픽 연산을 GPU로 오프로드하는 하드웨어가속을 사용할 수 있고 브라우저 렌더링 과정 중 마지막 컴포짓 단계에서 transform 혹은 opacity와 같은 속성은 GPU를 사용하여 레이어를 컴포짓하기에 렌더링 성능 향상이 될 수 있어 중요합니다.

### 정호's 답변: <!-- 답변 -->

## 🔗 꼬리질문: 웹 워커(Web Workers)에 대해 설명하고, 이것이 렌더링 성능에 어떻게 도움을 주는지 설명해주세요.

### 나라's 답변: 웹 동작을 백그라운드 스레드에서 실행할JavaScript코드를 작성할 수 있게 해주는 API입니다. JavaScript메인 스레드에서 독립적으로 실행되며 많은 계산이나 작업을 분리하여 처리할 수 있게 해줍니다.

### 슬기's 답변: 웹워커는 웹 애플리케이션에서 백그라운드 스레드에서 스크립트를 실행할 수 있게하는 API로 메인스레드와 독립적으로 동작하여 멀티스레딩을 가능하게 합니다.

### 정호's 답변: <!-- 답변 -->
